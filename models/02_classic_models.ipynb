{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeramirez169/DataScience_SGS_Classification/blob/main/models/02_classic_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVe5ljFZZoTt",
        "outputId": "019fb4d8-788d-4142-aa72-ba823bfc8f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DataScience_SGS_Classification'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 74 (delta 30), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (74/74), 23.94 MiB | 18.42 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "/content/DataScience_SGS_Classification/DataScience_SGS_Classification\n",
            "Collecting es-core-news-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.8.0/es_core_news_lg-3.8.0-py3-none-any.whl (568.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.0/568.0 MB\u001b[0m \u001b[31m757.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Clonar tu repositorio desde GitHub\n",
        "!git clone https://github.com/jeramirez169/DataScience_SGS_Classification.git\n",
        "%cd DataScience_SGS_Classification\n",
        "\n",
        "# Instalar dependencias necesarias\n",
        "!pip install -q pandas numpy scikit-learn unidecode spacy imbalanced-learn transformers\n",
        "!python -m spacy download es_core_news_lg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo2P_u6jZ9bn",
        "outputId": "5ad0d8ff-f201-47e6-d989-d9525cb7d1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DataScience_SGS_Classification/DataScience_SGS_Classification/data\n",
            "Archive:  Dataset SGS.zip\n",
            "  inflating: ./Dataset SGS.csv       \n",
            "/content/DataScience_SGS_Classification/DataScience_SGS_Classification\n"
          ]
        }
      ],
      "source": [
        "# Ir a la carpeta data\n",
        "%cd data\n",
        "\n",
        "# Descomprimir el archivo ZIP\n",
        "!unzip \"Dataset_SGS_clean.zip\" -d .\n",
        "\n",
        "# Regresar al directorio raíz del proyecto\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DTw9DpmmbCo8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Carga del dataset limpio\n",
        "ruta = \"data/Dataset_SGS_clean.csv\"   # Ajusta si tu ruta es distinta\n",
        "df = pd.read_csv(ruta, encoding=\"utf-8\")\n",
        "\n",
        "print(\"Columnas del dataset:\", df.columns.tolist())\n",
        "print(\"Tamaño del dataset:\", df.shape)\n",
        "\n",
        "#Definición de variables X (texto) e y (etiqueta)\n",
        "X = df[\"texto_truncado_lematizado\"]\n",
        "y = df[\"Oficina\"]\n",
        "\n",
        "# 3. Partición Train/Test (para ambos modelos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.20,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Tamaño entrenamiento:\", X_train.shape[0])\n",
        "print(\"Tamaño prueba:\", X_test.shape[0])\n",
        "\n",
        "#\n",
        "# Vectorización TF-IDF\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=3,\n",
        "    max_df=0.95,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(\"Forma de la matriz TF-IDF (train):\", X_train_tfidf.shape)\n",
        "\n",
        "# MODELO SVM\n",
        "svm_model = LinearSVC(\n",
        "    C=1.0,\n",
        "    loss=\"squared_hinge\",\n",
        "    class_weight=\"balanced\",\n",
        "    max_iter=5000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTADOS SVM\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Matriz de confusión SVM\n",
        "labels = sorted(y.unique())\n",
        "\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm_svm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title(\"Matriz de Confusión – SVM\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#MODELO XGBOOST\n",
        "\n",
        "# Codificación de etiquetas\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)\n",
        "\n",
        "print(\"\\nMapeo de etiquetas (clase → código):\")\n",
        "for cls, code in zip(le.classes_, le.transform(le.classes_)):\n",
        "    print(f\"{cls:25s} -> {code}\")\n",
        "\n",
        "# Definición del modelo XGBoost\n",
        "xgb_model = XGBClassifier(\n",
        "    objective=\"multi:softprob\",\n",
        "    num_class=len(le.classes_),\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=300,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_alpha=1.0,\n",
        "    reg_lambda=1.0,\n",
        "    tree_method=\"gpu_hist\",\n",
        "    predictor=\"gpu_predictor\",\n",
        "    eval_metric=\"mlogloss\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando XGBoost (puede tardar varios minutos)...\")\n",
        "xgb_model.fit(X_train_tfidf, y_train_enc)\n",
        "\n",
        "y_pred_xgb_enc = xgb_model.predict(X_test_tfidf)\n",
        "y_pred_xgb = le.inverse_transform(y_pred_xgb_enc)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTADOS XGBOOST\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "\n",
        "# Matriz de confusión XGBoost\n",
        "cm_xgb = confusion_matrix(y_test, y_pred_xgb, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm_xgb, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title(\"Matriz de Confusión – XGBoost\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Matriz de confusión normalizada XGBoost\n",
        "cm_xgb_norm = cm_xgb.astype(\"float\") / cm_xgb.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm_xgb_norm, annot=True, fmt=\".2f\", cmap=\"Greens\",\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title(\"Matriz de Confusión Normalizada – XGBoost\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Guardado de modelos y vectorizador\n",
        "joblib.dump(tfidf, \"models/tfidf_vectorizer.pkl\")\n",
        "joblib.dump(svm_model, \"models/svm_model.pkl\")\n",
        "joblib.dump(xgb_model, \"models/xgb_model_gpu.pkl\")\n",
        "\n",
        "print(\"\\nModelos y vectorizador guardados en carpeta 'models/'.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}